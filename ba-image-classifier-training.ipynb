{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BA Parking Lot Classifier",
      "provenance": [],
      "collapsed_sections": [
        "n_JfX6T92mBU",
        "4TtD2AqM21MI"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oYM61xrTsP5d"
      },
      "source": [
        "# Image Classifier Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bL54LWCHt5q5"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dlauq-4FWGZM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "f10cf39d-38ed-4904-d337-90886a0cf641"
      },
      "source": [
        "import itertools\n",
        "import os\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"Hub version:\", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TF version: 2.3.0\n",
            "Hub version: 0.9.0\n",
            "WARNING:tensorflow:From <ipython-input-1-0831fa394ed3>:12: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_JfX6T92mBU",
        "colab_type": "text"
      },
      "source": [
        "## Download Datasets\n",
        "\n",
        "Downloads PKLot, CNR-Park and CNR-EXT Datasets for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /content\n",
        "%mkdir -p datasets/{processed,source}\n",
        "\n",
        "!wget http://www.inf.ufpr.br/vri/databases/PKLot.tar.gz\n",
        "!wget http://cnrpark.it/dataset/CNR-EXT-Patches-150x150.zip\n",
        "!wget http://cnrpark.it/dataset/CNRPark-Patches-150x150.zip\n",
        "\n",
        "!tar -xvzf /content/PKLot.tar.gz -C /content/datasets/source\n",
        "!unzip /content/CNR-EXT-Patches-150x150.zip -d /content/datasets/source/CNR-EXT-Patches-150x150\n",
        "!unzip /content/CNRPark-Patches-150x150.zip -d /content/datasets/source/CNRPark-Patches-150x150\n",
        "\n",
        "!rm -rf /content/PKLot.tar.gz\n",
        "!rm -rf /content/CNR-EXT-Patches-150x150.zip\n",
        "!rm -rf /content/CNRPark-Patches-150x150.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TtD2AqM21MI",
        "colab_type": "text"
      },
      "source": [
        "## Copy images\n",
        "Copy images according to their folder according to their class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "from shutil import copyfile\n",
        "import math\n",
        "import random\n",
        "\n",
        "CNR_EXT_PATH = '/content/datasets/source/CNR-EXT-Patches-150x150'\n",
        "CNR_PARK_PATH = '/content/datasets/source/CNRPark-Patches-150x150'\n",
        "PKLOT_PATH = '/content/datasets/source/PKLot'\n",
        "\n",
        "DESTINATION = '/content/datasets/processed'\n",
        "\n",
        "EMPTY_DIR = os.path.join(DESTINATION, 'empty')\n",
        "OCCUPIED_DIR = os.path.join(DESTINATION, 'occupied')\n",
        "\n",
        "def setup_folders():\n",
        "    if not os.path.exists(EMPTY_DIR):\n",
        "        os.makedirs(EMPTY_DIR)\n",
        "    if not os.path.exists(OCCUPIED_DIR):\n",
        "        os.makedirs(OCCUPIED_DIR)\n",
        "\n",
        "def copy_images(source_dir, image_class):\n",
        "    # create list of all images in dir\n",
        "    image_list = [f for f in os.listdir(source_dir)\n",
        "        if re.search(r'([a-zA-Z0-9\\s_\\\\.\\-\\(\\):])+(.jpg|.jpeg|.png)$', f)]\n",
        "\n",
        "    for filename in image_list:\n",
        "        if os.path.isfile(os.path.join(source_dir, filename)):\n",
        "            if image_class == 0:\n",
        "                copyfile(\n",
        "                    os.path.join(source_dir, filename),\n",
        "                    os.path.join(EMPTY_DIR, filename)\n",
        "                )\n",
        "            elif image_class == 1:\n",
        "                copyfile(\n",
        "                    os.path.join(source_dir, filename),\n",
        "                    os.path.join(OCCUPIED_DIR, filename)\n",
        "                )\n",
        "\n",
        "def copy_cnr_park(path):\n",
        "    print('Copying CNR Park Dataset...')\n",
        "    for camera in os.listdir(path):\n",
        "        if camera.startswith('.'): continue # ignore hidden files\n",
        "        camera_path = os.path.join(path, camera)\n",
        "        for image_dir in os.listdir(camera_path):\n",
        "            if image_dir.startswith('.'): continue # ignore hidden files\n",
        "            dir = os.path.join(camera_path, image_dir)\n",
        "            if image_dir == 'busy':\n",
        "                print('Copying ' + dir)\n",
        "                copy_images(dir, 1)\n",
        "            if image_dir == 'free':\n",
        "                print('Copying ' + dir)\n",
        "                copy_images(dir, 0)\n",
        "    print('Finished')\n",
        "\n",
        "def copy_pklot(path):\n",
        "    print('Copying PKLot Dataset...')\n",
        "    patches_path = os.path.join(path, 'PKLotSegmented')\n",
        "\n",
        "    for camera in os.listdir(patches_path):\n",
        "        if camera.startswith('.'): continue # ignore hidden files\n",
        "        camera_dir = os.path.join(patches_path, camera)\n",
        "\n",
        "        for weather in os.listdir(camera_dir):\n",
        "            if weather.startswith('.'): continue # ignore hidden files\n",
        "            weather_dir = os.path.join(camera_dir, weather)\n",
        "\n",
        "            for date in os.listdir(weather_dir):\n",
        "                if date.startswith('.'): continue # ignore hidden files\n",
        "                date_dir = os.path.join(weather_dir, date)\n",
        "\n",
        "                for image_dir in os.listdir(date_dir):\n",
        "                    if image_dir.startswith('.'): continue # ignore hidden files\n",
        "                    dir = os.path.join(date_dir, image_dir)\n",
        "                    if image_dir == 'Occupied':\n",
        "                        print('Copying ' + dir)\n",
        "                        copy_images(dir, 1)\n",
        "                    if image_dir == 'Empty':\n",
        "                        print('Copying ' + dir)\n",
        "                        copy_images(dir, 0)\n",
        "    print('Finished')\n",
        "\n",
        "def copy_cnr_ext(path):\n",
        "    print('Copying CNR EXT Dataset...')\n",
        "\n",
        "    labels_path = os.path.join(path, 'LABELS/all.txt')\n",
        "    labels_file = open(labels_path, 'r')\n",
        "    labels = labels_file.readlines()\n",
        "\n",
        "    for label in labels:\n",
        "        file = label.strip().split()[0]\n",
        "        image_class = label.strip().split()[1]\n",
        "        file_name = os.path.basename(file)\n",
        "        image_path = os.path.join(path, 'PATCHES/' + file)\n",
        "\n",
        "        if os.path.isfile(image_path):\n",
        "            if image_class == '0':\n",
        "                copyfile(\n",
        "                    image_path,\n",
        "                    os.path.join(EMPTY_DIR, file_name)\n",
        "                )\n",
        "            elif label == '1':\n",
        "                copyfile(\n",
        "                    image_path,\n",
        "                    os.path.join(OCCUPIED_DIR, file_name)\n",
        "                )\n",
        "\n",
        "    print('Finished')\n",
        "\n",
        "setup_folders()\n",
        "copy_cnr_park(CNR_PARK_PATH)\n",
        "copy_pklot(PKLOT_PATH)\n",
        "copy_cnr_ext(CNR_EXT_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mmaHHH7Pvmth"
      },
      "source": [
        "## Select the TF2 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FlsEcKVeuCnf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6476c2a4-0ae2-43a1-9766-0b2fdab67801"
      },
      "source": [
        "module_selection = (\"mobilenet_v2_100_224\", 224)\n",
        "handle_base, pixels = module_selection\n",
        "MODULE_HANDLE =\"https://tfhub.dev/google/imagenet/{}/feature_vector/4\".format(handle_base)\n",
        "IMAGE_SIZE = (pixels, pixels)\n",
        "print(\"Using {} with input size {}\".format(MODULE_HANDLE, IMAGE_SIZE))\n",
        "\n",
        "BATCH_SIZE = 32"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4 with input size (224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yTY8qzyYv3vl"
      },
      "source": [
        "## Set up the dataset\n",
        "\n",
        "Resize images, split dataset into 0.25 validation and 0.75 training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WBtFK1hO8KsO",
        "colab": {}
      },
      "source": [
        "data_dir = '/content/datasets/processed'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "umB5tswsfTEQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4eb85f5b-c360-400b-dc22-f1b6dd806ac9"
      },
      "source": [
        "datagen_kwargs = dict(rescale=1./255, validation_split=.25)\n",
        "dataflow_kwargs = dict(target_size=IMAGE_SIZE, batch_size=BATCH_SIZE,\n",
        "                   interpolation=\"bilinear\")\n",
        "\n",
        "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    **datagen_kwargs)\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    data_dir, subset=\"validation\", shuffle=False, **dataflow_kwargs)\n",
        "\n",
        "train_datagen = valid_datagen\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir, subset=\"training\", shuffle=True, **dataflow_kwargs)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 193522 images belonging to 2 classes.\n",
            "Found 580571 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FS_gVStowW3G"
      },
      "source": [
        "## Defining the model\n",
        "\n",
        "Put a linear classifier on top of the `feature_extractor_layer` with the Hub module.\n",
        "\n",
        "Enable fine-tuning to train params of feature extractor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RaJW3XrPyFiF",
        "colab": {}
      },
      "source": [
        "do_fine_tuning = True #@param {type:\"boolean\"}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "50FYNIb1dmJH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "0720b36e-b831-4277-e2e1-1ff367199af9"
      },
      "source": [
        "print(\"Building model with\", MODULE_HANDLE)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\n",
        "    hub.KerasLayer(MODULE_HANDLE, trainable=do_fine_tuning),\n",
        "    tf.keras.layers.Dropout(rate=0.2),\n",
        "    tf.keras.layers.Dense(train_generator.num_classes,\n",
        "                          kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n",
        "])\n",
        "model.build((None,)+IMAGE_SIZE+(3,))\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building model with https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer (KerasLayer)     (None, 1280)              2257984   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 2562      \n",
            "=================================================================\n",
            "Total params: 2,260,546\n",
            "Trainable params: 2,226,434\n",
            "Non-trainable params: 34,112\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u2e5WupIw2N2"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9f3yBUvkd_VJ",
        "colab": {}
      },
      "source": [
        "model.compile(\n",
        "  optimizer=tf.keras.optimizers.SGD(lr=0.005, momentum=0.9), \n",
        "  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n",
        "  metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w_YKX2Qnfg6x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "2ad0704b-6c6e-4ee6-830c-56405a9bdfe0"
      },
      "source": [
        "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
        "validation_steps = valid_generator.samples // valid_generator.batch_size\n",
        "hist = model.fit(\n",
        "    train_generator,\n",
        "    epochs=3, steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=validation_steps).history"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "    2/18142 [..............................] - ETA: 47:23 - loss: 0.7769 - accuracy: 0.6250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1002s vs `on_train_batch_end` time: 0.2117s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1002s vs `on_train_batch_end` time: 0.2117s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "18142/18142 [==============================] - 6122s 337ms/step - loss: 0.2843 - accuracy: 0.9986 - val_loss: 0.2805 - val_accuracy: 0.9984\n",
            "Epoch 2/3\n",
            "18142/18142 [==============================] - 6209s 342ms/step - loss: 0.2751 - accuracy: 0.9996 - val_loss: 0.2750 - val_accuracy: 0.9983\n",
            "Epoch 3/3\n",
            "18142/18142 [==============================] - 6144s 339ms/step - loss: 0.2694 - accuracy: 0.9997 - val_loss: 0.2692 - val_accuracy: 0.9987\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CYOw0fTO1W4x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 566
        },
        "outputId": "6e9657b2-79ac-4e72-e5e3-6ee96dc3f061"
      },
      "source": [
        "plt.figure()\n",
        "plt.ylabel(\"Loss (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,2])\n",
        "plt.plot(hist[\"loss\"])\n",
        "plt.plot(hist[\"val_loss\"])\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Accuracy (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(hist[\"accuracy\"])\n",
        "plt.plot(hist[\"val_accuracy\"])\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f693e8d6cc0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YCsAsQM1IRvA"
      },
      "source": [
        "Save trained model for deployment to TF Serving or TF Lite (on mobile)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LGvTi69oIc2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "3cc4fbe9-d2f6-497a-a69f-51b7b583af99"
      },
      "source": [
        "saved_model_path = \"/content/park_mobilenet_v2_100_224\"\n",
        "tf.saved_model.save(model, saved_model_path)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/park_mobilenet_v2_100_224/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/park_mobilenet_v2_100_224/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iKDOCme0m1E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6691eebe-9e96-4aa8-c0aa-b8872aff15f5"
      },
      "source": [
        "%cd /content\n",
        "!tar -cf park_mobilenet_v2_100_224.tar park_mobilenet_v2_100_224/"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8r_pIRQ1L52",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QzW4oNRjILaq"
      },
      "source": [
        "## Convert for TensorFlow Lite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Va1Vo92fSyV6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e10b983-a18a-435e-c264-9d1a09257ef2"
      },
      "source": [
        "optimize_lite_model = True  #@param {type:\"boolean\"}\n",
        "#@markdown Setting a value greater than zero enables quantization of neural network activations. A few dozen is already a useful amount.\n",
        "num_calibration_examples = 0  #@param {type:\"slider\", min:0, max:1000, step:1}\n",
        "representative_dataset = None\n",
        "if optimize_lite_model and num_calibration_examples:\n",
        "  # Use a bounded number of training examples without labels for calibration.\n",
        "  # TFLiteConverter expects a list of input tensors, each with batch size 1.\n",
        "  representative_dataset = lambda: itertools.islice(\n",
        "      ([image[None, ...]] for batch, _ in train_generator for image in batch),\n",
        "      num_calibration_examples)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_path)\n",
        "if optimize_lite_model:\n",
        "  converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "  if representative_dataset:  # This is optional, see above.\n",
        "    converter.representative_dataset = representative_dataset\n",
        "lite_model_content = converter.convert()\n",
        "\n",
        "with open(\"/content/park_mobilenet_v2_100_224_lite\", \"wb\") as f:\n",
        "  f.write(lite_model_content)\n",
        "print(\"Wrote %sTFLite model of %d bytes.\" %\n",
        "      (\"optimized \" if optimize_lite_model else \"\", len(lite_model_content)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wrote optimized TFLite model of 2390240 bytes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_wqEmD0xIqeG",
        "colab": {}
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_content=lite_model_content)\n",
        "def lite_model(images):\n",
        "  interpreter.allocate_tensors()\n",
        "  interpreter.set_tensor(interpreter.get_input_details()[0]['index'], images)\n",
        "  interpreter.invoke()\n",
        "  return interpreter.get_tensor(interpreter.get_output_details()[0]['index'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JMMK-fZrKrk8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "66736400-d770-4362-e265-f31b91881416"
      },
      "source": [
        "num_eval_examples = 200 \n",
        "eval_dataset = ((image, label)  # TFLite expects batch size 1.\n",
        "                for batch in train_generator\n",
        "                for (image, label) in zip(*batch))\n",
        "count = 0\n",
        "count_lite_tf_agree = 0\n",
        "count_lite_correct = 0\n",
        "for image, label in eval_dataset:\n",
        "  probs_lite = lite_model(image[None, ...])[0]\n",
        "  probs_tf = model(image[None, ...]).numpy()[0]\n",
        "  y_lite = np.argmax(probs_lite)\n",
        "  y_tf = np.argmax(probs_tf)\n",
        "  y_true = np.argmax(label)\n",
        "  count +=1\n",
        "  if y_lite == y_tf: count_lite_tf_agree += 1\n",
        "  if y_lite == y_true: count_lite_correct += 1\n",
        "  if count >= num_eval_examples: break\n",
        "print(\"TF Lite model agrees with original model on %d of %d examples (%g%%).\" %\n",
        "      (count_lite_tf_agree, count, 100.0 * count_lite_tf_agree / count))\n",
        "print(\"TF Lite model is accurate on %d of %d examples (%g%%).\" %\n",
        "      (count_lite_correct, count, 100.0 * count_lite_correct / count))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TF Lite model agrees with original model on 200 of 200 examples (100%).\n",
            "TF Lite model is accurate on 200 of 200 examples (100%).\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}